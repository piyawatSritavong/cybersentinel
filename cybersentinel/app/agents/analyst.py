from langchain_groq import ChatGroq
from app.core.config import settings
from app.core.memory import memory  # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
import logging
import asyncio
import json
import re

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Logging
logging.basicConfig(level=logging.INFO)


class LogAnalyzer:

    def __init__(self):
        self.name = "CyberSentinel AI"
        try:
            self.llm = ChatGroq(
                api_key=settings.groq_api_key,
                model_name=settings.analyst_model,
                temperature=0.1,
            )
        except Exception as e:
            logging.error(f"Failed to initialize ChatGroq: {e}")
            self.llm = None

    async def analyze_log(self, log_text: str):
        if not self.llm:
            return {
                "risk_level": "Error",
                "category": "Internal",
                "summary": "AI Model not configured"
            }

        # --- STEP 1: Check Vector Memory (‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå) ---
        logging.info("üß† Searching vector memory for similar cases...")
        similar_cases = memory.get_similar_cases(log_text, n_results=1)

        if similar_cases:
            logging.info("‚ôªÔ∏è  Found similar patterns in experience.")
            context_from_memory = similar_cases[0]
        else:
            logging.info(
                "üÜï No similar cases found. This is a new learning opportunity."
            )
            context_from_memory = "No historical context available."

        # --- STEP 2: Construct Prompt ---
        prompt = f"""You are a Tier 1 SOC Analyst with Self-Learning capabilities.

INPUT LOG TO INVESTIGATE:
{log_text}

HISTORICAL CONTEXT (From your memory):
{context_from_memory}

YOUR TASK:
1. Compare the INPUT LOG with HISTORICAL CONTEXT.
2. Provide the risk level, category, and a concise summary.

OUTPUT FORMAT (Strictly JSON):
{{
    "risk_level": "Low/Medium/High/Critical",
    "category": "Event Category",
    "summary": "Your analysis + recommended action based on SOP"
}}
"""

        try:
            # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ AI
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, lambda: self.llm.invoke(prompt))

            # Clean & Parse JSON
            json_match = re.search(r'\{.*\}', response.content, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())

                # --- [‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏ö memory.save_incident ‡∏≠‡∏≠‡∏Å] ---
                # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏™‡∏±‡πà‡∏á Save ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ main.py ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ID ‡∏ã‡πâ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ

                return analysis

        except Exception as e:
            logging.error(f"Analyst Agent error: {e}")
            return {
                "risk_level": "High",
                "category": "System Error",
                "summary": f"Failed to analyze: {str(e)}"
            }


# ‡∏™‡∏£‡πâ‡∏≤‡∏á Instance ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
log_analyzer = LogAnalyzer()
